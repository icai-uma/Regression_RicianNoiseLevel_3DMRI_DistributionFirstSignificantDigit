{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding noise to 3D MRI\n",
    "\n",
    "This script adds noise to the MRI and saves the noise levels in an excel file and the noise images in a directory.\n",
    "You can choose to save to your computer or to an external device. To do this, just run the correct chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T08:03:35.175921156Z",
     "start_time": "2023-07-12T08:03:32.720375721Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T08:03:37.072518826Z",
     "start_time": "2023-07-12T08:03:37.016682146Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "# Import the scipy package\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for Mindboggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Define the dataset to use, choosing one of the directories: 20OASIS_SynapseWeb_brain, OASIS-TRT-20_volumes, 12HLN, NKI-TRT-20_volumes, NKI-RS-22_volumes, MMRR-21_volumes\n",
    "repository = '12HLN' #20OASIS_SynapseWeb_brain #OASIS-TRT-20_volumes #12HLN #NKI-TRT-20_volumes #NKI-RS-22_volumes #MMRR-21_volumes\n",
    "\n",
    "# Directories\n",
    "inputDir = ('../input')  # Directory where you want to search for MRI files\n",
    "outputDir = ('../output')\n",
    "outputInputDir = outputDir + '/input/'\n",
    "\n",
    "# output path file\n",
    "extension = '.pkl'\n",
    "outputFile = repository + extension\n",
    "dataset_path = os.path.join(outputInputDir, outputFile)\n",
    "\n",
    "# Path with input images\n",
    "dataMRI = os.path.join(inputDir, repository)\n",
    "typeImage = 't1weighted.nii.gz' #'t1weighted_brain.nii.gz' #'t1weighted.nii.gz'\n",
    "pathMRI = sorted(glob(dataMRI + '/**/' + typeImage, recursive=True))\n",
    "SIZE = len(pathMRI)\n",
    "\n",
    "print(f\"MRI in the path: {pathMRI}\")\n",
    "print(f\"Size is {SIZE}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for fsatMRI datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: define it\n",
    "# T1_AXIAL # Axial_T1_SE # AX_T1_3 # AX_T1_15 # AX_T1_FLASH_(POST) # AX_T1_POST_3 # AX_T1_POST_15 # T1_AXIAL # T1_AXIAL_POST_GAD\n",
    "repository = 'T1_AXIAL'\n",
    "\n",
    "# Directories\n",
    "inputDir = ('../input') \n",
    "outputDir = ('../output')\n",
    "outputInputDir = outputDir + '/input/'\n",
    "# Directory where you want to search for MRI files\n",
    "directory = '/home/rosammq/DATA/brain_FastMRI_DICOM/NIFTI'\n",
    "\n",
    "# output path file\n",
    "extension = '.pkl'\n",
    "outputFile = repository + extension\n",
    "dataset_path = os.path.join(outputInputDir, outputFile)\n",
    "\n",
    "# name of images\n",
    "input_csv = ('/home/rosammq/PROJECTS/Axioms2023/input/csv/fastMRI_brain_DICOM_' + repository + '.csv')\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(input_csv, index_col=None, header=None)\n",
    "# Auxiliar variable\n",
    "img_list = []\n",
    "\n",
    "# Path with input images\n",
    "for row_idx, row in df.iterrows():\n",
    "    file_path = directory + '/' + row.iloc[0]\n",
    "    print(f\"MRI in the path: {file_path}\")\n",
    "    img_list.append(file_path)\n",
    "\n",
    "\n",
    "pathMRI = img_list\n",
    "SIZE = len(img_list)\n",
    "print(f\"Size is {SIZE}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only run the following chunk is you want to save the result in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../output/noise_dataset' was already created\n",
      "Directory '../output/noise_dataset/AX_T1_POST_3_new' created\n"
     ]
    }
   ],
   "source": [
    "# Create/check the directory to output\n",
    "directory1 = noiseDir\n",
    "if os.path.isdir(directory1):\n",
    "    print(\"Directory '% s' was already created\" % directory1)\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(directory1)\n",
    "    except OSError:\n",
    "        print(\"Directory '% s' failed\" % directory1)\n",
    "    else:\n",
    "        print(\"Directory '% s' created\" % directory1)\n",
    "\n",
    "# Create/check a directory for the output in this file but this will be the input in another file\n",
    "directory2 = result_path\n",
    "if os.path.isdir(directory2):\n",
    "    print(\"Directory '% s' was already created\" % directory2)\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(directory2)\n",
    "    except OSError:\n",
    "        print(\"Directory '% s' failed\" % directory2)\n",
    "    else:\n",
    "        print(\"Directory '% s' created\" % directory2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only run the two followings chunk is you want to save the results in an external disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save in hard disc:\n",
    "noiseDir = \"/media/rosammq/My Passport/Rosammq/noiseDataset_Axioms2023\"\n",
    "external_dir = os.path.join(noiseDir, repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/media/rosammq/My Passport/Rosammq/noiseDataset_Axioms2023/AX_T1_POST_15' created\n"
     ]
    }
   ],
   "source": [
    "directory3 = external_dir\n",
    "if os.path.isdir(directory3):\n",
    "    print(\"Directory '% s' was already created\" % directory3)\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(directory3)\n",
    "    except OSError:\n",
    "        print(\"Directory '% s' failed\" % directory3)\n",
    "    else:\n",
    "        print(\"Directory '% s' created\" % directory3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to create the noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T08:03:52.130283564Z",
     "start_time": "2023-07-12T08:03:52.128146972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the experiment parameters\n",
    "NumNoiseLevels=20\n",
    "NumNoiselessImages=SIZE\n",
    "MaxNoiseLevel=0.4\n",
    "\n",
    "# Generate the randomly chosen noise levels\n",
    "np.random.seed(seed=1)\n",
    "NoiseLevels = np.random.uniform(0,MaxNoiseLevel,(NumNoiselessImages,NumNoiseLevels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T08:03:54.486614827Z",
     "start_time": "2023-07-12T08:03:54.475080067Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(NoiseLevels)\n",
    "df.to_excel(os.path.join(noiseDir+ '/%s/NoiseLevels_%s.xlsx' % (repository, repository)), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T08:04:01.725894923Z",
     "start_time": "2023-07-12T08:04:01.723298083Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Rician noise to a 3D MRI\n",
    "# Inputs:\n",
    "#     img3D=The noiseless 3D MRI as a numpy 3D array\n",
    "#     StandardDeviation=The standard deviation of the Rician noise\n",
    "#     NoiseScale=Scaling parameter for the noise\n",
    "#     fixedSeed=Pseudorandom seed to be employed in the noise generation\n",
    "# Output:\n",
    "#     module=The noisy module 3D MRI as a numpy 3D array\n",
    "def ricianDistribution(img3D, StandardDeviation, NoiseScale, fixedSeed):\n",
    "    if StandardDeviation==0:\n",
    "        return img3D\n",
    "    np.random.seed(seed=fixedSeed)\n",
    "    distributionRandom1 = np.random.normal(size = img3D.shape)\n",
    "    distributionRandom2 = np.random.normal(size = img3D.shape)\n",
    "    # Generate the noise\n",
    "    x = StandardDeviation * NoiseScale * distributionRandom1 + img3D\n",
    "    y = StandardDeviation * NoiseScale * distributionRandom2\n",
    "    module = np.sqrt(pow(x, 2) + pow(y, 2))\n",
    "    # Return the image with noise\n",
    "    return  module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to generate the noise images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T08:16:40.861522465Z",
     "start_time": "2023-07-12T08:04:06.103290188Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop for all noiseless images\n",
    "for NdxImage in range(0, NumNoiselessImages):\n",
    "\n",
    "  # Load the noiseless 3D MRI\n",
    "  NoiselessImage = nib.load(pathMRI[NdxImage]).get_fdata()\n",
    "\n",
    "  # The interquartile range is employed as the noise scaling parameter. This way the\n",
    "  # added noise level is robust against outliers in the values of the noiseless images.\n",
    "  MyIQR=scipy.stats.iqr(NoiselessImage[NoiselessImage!=0])\n",
    "\n",
    "  # Loop for all randomly chosen noise levels\n",
    "  for NdxNoise in range(0, NumNoiseLevels):\n",
    "\n",
    "    # Apply Rician noise\n",
    "    NoiseLevel=NoiseLevels[NdxImage,NdxNoise]\n",
    "    NoisyImage = ricianDistribution(img3D=NoiselessImage,StandardDeviation=NoiseLevel,NoiseScale=MyIQR,fixedSeed=NdxImage*NumNoiseLevels+NdxNoise)\n",
    "    img = nib.Nifti1Image(NoisyImage, np.eye(4))  # Save axis for data (just identity)\n",
    "    img.to_filename(os.path.join(noiseDir+ '/%s/Image%s_Noise%s.nii.gz' % (repository, NdxImage, NdxNoise)) ) # Save as NIfTI file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benford040",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18 (default, Sep 11 2023, 13:40:15) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e168a325c0c280b551173248b6d4b0c85882bf0215c04a8e6edfcd8716a8cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
