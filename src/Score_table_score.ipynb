{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benford for 3D MRI - Training data generation\n",
    "\n",
    "This scripts generates score list using all repositories by each performance measures.\n",
    "Therefore you need to select the performance measures option you want to run: 0 = MSE, 1 = MAE, 2 = R2\n",
    "\n",
    "Before to run this script you must to put the xlsx files with the result of the CrossValidation results in the path '../input/input_to_do_score\n",
    "The output is a xlsx file with the Metrics and the Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# SELECT THE MEASURE OPTION: \n",
    "sheet_name = 2 # 0 = MSE, 1 = MAE, 2 = R2\n",
    "\n",
    "#Path\n",
    "table_switch = {\n",
    "        '0': 'MSE',\n",
    "        '1': 'MAE',\n",
    "        '2': 'R2'\n",
    "    }\n",
    "\n",
    "nameOutput = table_switch.get(str(sheet_name))\n",
    "inputDir = ('../output/input_to_do_score') \n",
    "outputDir = '../output/Score_' + nameOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../output/Score_R2' created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create/check the directory to output\n",
    "directory1 = outputDir\n",
    "\n",
    "if os.path.isdir(directory1):\n",
    "    print(\"Directory '% s' was already created\" % directory1)\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(directory1)\n",
    "    except OSError:\n",
    "        print(\"Directory '% s' failed\" % directory1)\n",
    "    else:\n",
    "        print(\"Directory '% s' created\" % directory1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(filename):\n",
    "    \n",
    "    # Read dataset\n",
    "    original_data = pd.read_excel(os.path.join(inputDir, filename), sheet_name=sheet_name)\n",
    "\n",
    "    # Create dataframes\n",
    "    column_names = [\"Metrics\", \"Score\"]\n",
    "    df_data = pd.DataFrame(columns = column_names)\n",
    "    # Write in the 'Metrics' colum the metrics of the excel files ('Unnamed: 7' column)\n",
    "    df_data['Metrics'] = original_data['Unnamed: 0']\n",
    "    \n",
    "    # size\n",
    "    size = original_data.iloc[:,1].size\n",
    "    print(f\"Size: {size}\")\n",
    "    # Create a list started in the most high value (xx) to score the metrics' appearance\n",
    "    list_score = list(reversed(range(1, df_data.shape[0]+1)))\n",
    "\n",
    "    # Assign list to 'Score' column\n",
    "    new_df_data = df_data.assign(Score = list_score)\n",
    "    print(new_df_data.iloc[0:3])\n",
    "\n",
    "    # Sort the dataset by 'Metrics' to have the same order in all dataset\n",
    "    sorted_df_data = new_df_data.sort_values('Metrics')\n",
    "\n",
    "    return sorted_df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "directory = ('../output/input_to_do_score') \n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "df_list = []\n",
    "name_list = []\n",
    "size = 120\n",
    "\n",
    "# Loop through the filenames\n",
    "for filename in files:\n",
    "    # Do something with each filename\n",
    "    print(filename)\n",
    "    dataset_processed = process_data(filename)\n",
    "    df_list.append(dataset_processed)\n",
    "    name_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the score values for each metric\n",
    "newList = []\n",
    "\n",
    "#Choose the dataset you want to use to do the score. \n",
    "\n",
    "# 1.5 Tesla: [0], [1], [2], [5], and [6]\n",
    "for i in range(size):\n",
    "\tnewList.append(df_list[0]['Score'].values.tolist()[i] +\n",
    "                      df_list[1]['Score'].values.tolist()[i] +\n",
    "                      df_list[2]['Score'].values.tolist()[i] +\n",
    "                      df_list[5]['Score'].values.tolist()[i] +\n",
    "                      df_list[6]['Score'].values.tolist()[i])\n",
    "\t\n",
    "\"\"\"\n",
    "# # For 3 Tesla: [3],  [4], and  [7]\n",
    "for i in range(size):\n",
    "\tnewList.append(df_list[3]['Score'].values.tolist()[i] +\n",
    "                      df_list[4]['Score'].values.tolist()[i] +\n",
    "                      df_list[7]['Score'].values.tolist()[i])\n",
    "\"\"\"\n",
    "\n",
    "print(newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T08:53:08.527034060Z",
     "start_time": "2023-07-10T08:53:08.523880357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe to save the Score list \n",
    "column_names = [\"Metrics\", \"Score\"]\n",
    "score_df = pd.DataFrame(columns = column_names)\n",
    "score_df['Metrics'] = df_list[0]['Metrics'].values.tolist()\n",
    "\n",
    "score_df.iloc[0:3]\n",
    "score_df['Score'] = newList\n",
    "score_df.iloc[0:3]\n",
    "\n",
    "score_sorted = score_df.sort_values('Score', ascending=False)\n",
    "\n",
    "# Save the score list\n",
    "score_sorted.to_excel(os.path.join(outputDir, \"Score\" + nameOutput + \".xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benford040",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e168a325c0c280b551173248b6d4b0c85882bf0215c04a8e6edfcd8716a8cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
